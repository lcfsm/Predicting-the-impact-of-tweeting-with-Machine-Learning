#eje vertical age, elbowbread
#eje horizontal,resto de variables
#En el grafico la suma de los porcentajes dos los ejes menos el 100%
#nos da la tasa de perdida que estamos teniendo (20,25%)
acp1$eig #vemos cuantos ejes mantener, con dos seria suficiente (valores por encima de 100/10variables=10), Dexfat y Age
rm(list = ls())
library(e1071)
plot(iris)
plot(iris$Sepal.Length, iris$Sepal.Width, col=iris$Species)
plot(iris$Petal.Length, iris$Pepal.Width, col=iris$Species)
s <- sample(150,100)
col <- c("Petal.Length", "Petal.Width", "Species")
iris_train <- iris[s,col]
iris_test <- iris[-s,col]
#Creamos un vectorerror para almacenar los errores que vayamos obteniendo
vectorerror <- rep()
#################### KERNEL LINEAR #######################################################
svmtune <- tune(svm,Species~.,data=iris_train,kernel="linear",ranges = list(cost=c(0.001,0.01,.1, 1, 10, 100)))
summary(svmtune)
svmfit<-svm(Species~.,data=iris_train,kernel="linear", cost=svmtune$best.parameters,scale=FALSE)
#print(svmfit)
plot(svmfit,iris_test[,col],type="class")
p<-predict(svmfit,iris_test[,col],type="class")
mean(p==iris_test[,3])
test_t = table(p,iris_test[,3])
test_t
error = 1-sum(diag(test_t))/nrow(iris_test)
#Añadimos al vectorerror la TEA en test
vectorerror <- append(vectorerror, error)
#################### KERNEL RADIAL "Gaussian" #######################################################
svmtune <- tune(svm, Species~.,data=iris_train, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
summary(svmtune)
svmtune$best.parameters$cost
#svmtune <- tune.svm(Species~.,data=iris_train, kernel="radial", cost=2^seq(-5,5,len=5),
#gamma=10^seq(-3,6,len=5), tunecontrol=tune.control(cross=5))
svmfit <- svm(Species ~ ., data=iris_train, kernel="radial", cost=svmtune$best.parameters$cost, gamma=svmtune$best.parameters$gamma)
#print(svmfit)
plot(svmfit,iris_test[,col],type="class")
p<-predict(svmfit,iris_test[,col],type="class")
mean(p==iris_test[,3])
test_t = table(p,iris_test[,3])
test_t
error = 1-sum(diag(test_t))/nrow(iris_test)
#Añadimos al vectorerror la TEA en test
vectorerror <- append(vectorerror, error)
##########################################################################################
#################### KERNEL SIGMOID #######################################################
svmtune <- tune(svm, Species~.,data=iris_train, kernel="sigmoid", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
summary(svmtune)
svmfit <- svm(Species ~ ., data=iris_train, kernel="sigmoid", cost=svmtune$best.parameters$cost, gamma=svmtune$best.parameters$gamma)
print(svmfit)
plot(svmfit,iris_test[,col],type="class")
p<-predict(svmfit,iris_test[,col],type="class")
mean(p==iris_test[,3])
test_t = table(p,iris_test[,3])
test_t
error = 1-sum(diag(test_t))/nrow(iris_test)
#Añadimos al vectorerror la TEA en test
vectorerror <- append(vectorerror, error)
##########################################################################################
#################### KERNEL POLYNOMIAL #######################################################
svmtune <- tune(svm, Species~.,data=iris_train, kernel="polynomial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
summary(svmtune)
svmfit <- svm(Species ~ ., data=iris_train, kernel="polynomial", cost=svmtune$best.parameters$cost, gamma=svmtune$best.parameters$gamma)
print(svmfit)
plot(svmfit,iris_test[,col],type="class")
p<-predict(svmfit,iris_test[,col],type="class")
mean(p==iris_test[,3])
test_t = table(p,iris_test[,3])
test_t
error = 1-sum(diag(test_t))/nrow(iris_test)
#Añadimos al vectorerror la TEA en test
vectorerror <- append(vectorerror, error)
##########################################################################################
##################### LIBRARY KERNLAB - Gaussian radial basis kernel rbfdot #######################################################
library(kernlab)
svmfit <- ksvm(Species~.,data=iris_train,kernel="rbfdot", kpar=list(sigma=0.015),C=70,cross=4,prob.model=TRUE)
print(svmfit)
p <- predict(svmfit,iris_test)
mean(p==iris_test[,3])
test_t = table(p,iris_test[,3])
test_t
error = 1-sum(diag(test_t))/nrow(iris_test)
#Añadimos al vectorerror la TEA en test
vectorerror <- append(vectorerror, error)
###########################################################################################
cat("El error para el Kernel Linear es:",vectorerror[1])
cat("El error para el Kernel Radial es:",vectorerror[2])
cat("El error para el Kernel Sigmoid es:",vectorerror[3])
cat("El error para el Kernel Polynomial es:",vectorerror[4])
cat("El error para LIBRARY KERNLAB - Kernel rbfdot(Gaussian radial basis) es:",vectorerror[5])
rm(list = ls())
library(e1071)
plot(iris)
plot(iris$Sepal.Length, iris$Sepal.Width, col=iris$Species)
plot(iris$Petal.Length, iris$Pepal.Width, col=iris$Species)
s <- sample(150,100)
col <- c("Petal.Length", "Petal.Width", "Species")
iris_train <- iris[s,col]
iris_test <- iris[-s,col]
#Creamos un vectorerror para almacenar los errores que vayamos obteniendo
vectorerror <- rep()
#################### KERNEL LINEAR #######################################################
svmtune <- tune(svm,Species~.,data=iris_train,kernel="linear",ranges = list(cost=c(0.001,0.01,.1, 1, 10, 100)))
summary(svmtune)
svmfit<-svm(Species~.,data=iris_train,kernel="linear", cost=svmtune$best.parameters,scale=FALSE)
#print(svmfit)
plot(svmfit,iris_test[,col],type="class")
p<-predict(svmfit,iris_test[,col],type="class")
mean(p==iris_test[,3])
test_t = table(p,iris_test[,3])
test_t
error = 1-sum(diag(test_t))/nrow(iris_test)
#Añadimos al vectorerror la TEA en test
vectorerror <- append(vectorerror, error)
#################### KERNEL RADIAL "Gaussian" #######################################################
svmtune <- tune(svm, Species~.,data=iris_train, kernel="radial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
summary(svmtune)
svmtune$best.parameters$cost
#svmtune <- tune.svm(Species~.,data=iris_train, kernel="radial", cost=2^seq(-5,5,len=5),
#gamma=10^seq(-3,6,len=5), tunecontrol=tune.control(cross=5))
svmfit <- svm(Species ~ ., data=iris_train, kernel="radial", cost=svmtune$best.parameters$cost, gamma=svmtune$best.parameters$gamma)
#print(svmfit)
plot(svmfit,iris_test[,col],type="class")
p<-predict(svmfit,iris_test[,col],type="class")
mean(p==iris_test[,3])
test_t = table(p,iris_test[,3])
test_t
error = 1-sum(diag(test_t))/nrow(iris_test)
#Añadimos al vectorerror la TEA en test
vectorerror <- append(vectorerror, error)
##########################################################################################
#################### KERNEL SIGMOID #######################################################
svmtune <- tune(svm, Species~.,data=iris_train, kernel="sigmoid", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
summary(svmtune)
svmfit <- svm(Species ~ ., data=iris_train, kernel="sigmoid", cost=svmtune$best.parameters$cost, gamma=svmtune$best.parameters$gamma)
print(svmfit)
plot(svmfit,iris_test[,col],type="class")
p<-predict(svmfit,iris_test[,col],type="class")
mean(p==iris_test[,3])
test_t = table(p,iris_test[,3])
test_t
error = 1-sum(diag(test_t))/nrow(iris_test)
#Añadimos al vectorerror la TEA en test
vectorerror <- append(vectorerror, error)
##########################################################################################
#################### KERNEL POLYNOMIAL #######################################################
svmtune <- tune(svm, Species~.,data=iris_train, kernel="polynomial", ranges=list(cost=10^(-1:2), gamma=c(.5,1,2)))
summary(svmtune)
svmfit <- svm(Species ~ ., data=iris_train, kernel="polynomial", cost=svmtune$best.parameters$cost, gamma=svmtune$best.parameters$gamma)
print(svmfit)
plot(svmfit,iris_test[,col],type="class")
p<-predict(svmfit,iris_test[,col],type="class")
mean(p==iris_test[,3])
test_t = table(p,iris_test[,3])
test_t
error = 1-sum(diag(test_t))/nrow(iris_test)
#Añadimos al vectorerror la TEA en test
vectorerror <- append(vectorerror, error)
##########################################################################################
##################### LIBRARY KERNLAB - Gaussian radial basis kernel rbfdot #######################################################
library(kernlab)
svmfit <- ksvm(Species~.,data=iris_train,kernel="rbfdot", kpar=list(sigma=0.015),C=70,cross=4,prob.model=TRUE)
print(svmfit)
p <- predict(svmfit,iris_test)
mean(p==iris_test[,3])
test_t = table(p,iris_test[,3])
test_t
error = 1-sum(diag(test_t))/nrow(iris_test)
#Añadimos al vectorerror la TEA en test
vectorerror <- append(vectorerror, error)
###########################################################################################
cat("El error para el Kernel Linear es:",vectorerror[1])
cat("El error para el Kernel Radial es:",vectorerror[2])
cat("El error para el Kernel Sigmoid es:",vectorerror[3])
cat("El error para el Kernel Polynomial es:",vectorerror[4])
cat("El error para LIBRARY KERNLAB - Kernel rbfdot(Gaussian radial basis) es:",vectorerror[5])
#No se aprecian resultados muy diferentes entre todos los Kernels probados, sin embargo
#el Kernel Sigmoid arroja en muchos casos resultado en TAE ligeramente inferior en un alto porcentaje
#de las puebas realizadas, aunque todo depende de la aleatoridad de la muestra.
rm(list = ls())
data("bodyfat", package="TH.data")
str(bodyfat)
cor(bodyfat) #vemos que variables estan correlacionadas
View(bodyfat)
bodyfat[,2]<-NULL
View(bodyfat)
rm(list = ls())
data("bodyfat", package="TH.data")
str(bodyfat)
bodyfat[,2]<-NULL
cor(bodyfat) #vemos que variables estan correlacionadas
library(FactoMineR)
acp1<-PCA(bodyfat)
summary(acp1)
plot(pc)
#eje vertical age, elbowbread
rm(list = ls())
data("bodyfat", package="TH.data")
str(bodyfat)
bodyfat[,2]<-NULL
cor(bodyfat) #vemos que variables estan correlacionadas
library(FactoMineR)
acp1<-PCA(bodyfat)
summary(acp1)
#eje vertical age, elbowbread
#eje horizontal,resto de variables
#En el grafico la suma de los porcentajes dos los ejes menos el 100%
#nos da la tasa de perdida que estamos teniendo (20,25%)
acp1$eig #vemos cuantos ejes mantener, con dos seria suficiente (valores por encima de 100/10variables=10), Dexfat y Age
acp1$var$coord
plot(acp1, choix="ind", axes=c(1,2,3)) #visualizamos por los ejes 1 ,2
plot(acp1, choix="var", axes=c(1,2,3))
acp1$ind$cos2 #vemos que variables no estan bien representadas, como se reparte la inercia en los cuatro ejes
library(twitteR)
library(RCurl)
library(RJSONIO)
library(stringr)
# Declare Twitter API Credentials
api_key <- "H4w4mdUSP3Fht1MltVnLYtNEN" # From dev.twitter.com
api_secret <- "lhcUfQoQxpFJSaJsvJdNDHCieFdjVASHAbPNklLNmP4RjmtH2W" # From dev.twitter.com
token <- "753784038-uv8QL27Zlo5kphRM8UYfVXNzbcbjFF7sdYh1uY15" # From dev.twitter.com
token_secret <- "EPHvdgWEQnb2I7zAEqLOz4uPJCof4o1FuwcFSgP3XK3T8" # From dev.twitter.com
# Create Twitter Connection
setup_twitter_oauth(api_key, api_secret, token, token_secret)
#Now to test to see if connection is good
searchTwitter('analytics')
searchTwitter('analytics')
install.packages("C:/Users/LAPTOP/Downloads/cldr_1.1.0.tar.gz", repos = NULL, type = "source")
lapply(tweets, function(x) EnlishWordComparisonList %in% x)
EnglishWordComparisonList<-as.vector(source("C:\Users\LAPTOP\Desktop\PFM\src"))
EnglishWordComparisonList<-as.vector(source("C:\\Users\\LAPTOP\\Desktop\\PFM\\src"))
EnglishWordComparisonList<-as.vector(source("C:\\Users\\LAPTOP\\Desktop\\PFM\\src\\wordsEn.txt"))
palabras = read.csv("wordsEn.txt")
EnglishWordComparisonList<-as.vector(source("C:\\Users\\LAPTOP\\Desktop\\PFM\\src\\wordsEn.txt"))
EnglishWordComparisonList<-as.vector(source("C:\\Users\\LAPTOP\\Desktop\\PFM\\src\\wordsEn.txt"))
Englishinator<-function(tweet, threshold = .06) {
EnglishWordComparisonList<-as.vector(source("C:\\Users\\LAPTOP\\Desktop\\PFM\\src\\wordsEn.txt"))
EnglishWordComparisonList
rm(list = ls())
#install.packages("twitteR", "RCurl", "RJSONIO", "stringr")
library(twitteR)
library(RCurl)
library(RJSONIO)
library(stringr)
library(igraph)
# Declare Twitter API Credentials
api_key <- "H4w4mdUSP3Fht1MltVnLYtNEN" # From dev.twitter.com
api_secret <- "lhcUfQoQxpFJSaJsvJdNDHCieFdjVASHAbPNklLNmP4RjmtH2W" # From dev.twitter.com
token <- "753784038-uv8QL27Zlo5kphRM8UYfVXNzbcbjFF7sdYh1uY15" # From dev.twitter.com
token_secret <- "EPHvdgWEQnb2I7zAEqLOz4uPJCof4o1FuwcFSgP3XK3T8" # From dev.twitter.com
# Create Twitter Connection
setup_twitter_oauth(api_key, api_secret, token, token_secret)
#Now to test to see if connection is good
searchTwitter('analytics')
tl <- userTimeline('luiscar_com', n=6)
df <- do.call(rbind, lapply(tl, function(x) x$toDataFrame()))
df
names(df)
df[, c("created", "retweetCount")]
tl <- userTimeline('luiscar_com', n=100)
df <- do.call(rbind, lapply(tl, function(x) x$toDataFrame()))
names(df)
df[, c("created", "retweetCount")]
tl
times <- lapply(tl, function(x) x$created)
times
these <- which(times > beginning & times < end)
myMorningTweetsDF <- twListToDF(tl)
myMorningTweetsDF
View(myMorningTweetsDF)
myTweetsDF <- twListToDF(tl)
View(myTweetsDF)
library(readr)
ozone <- read_csv("C:/Users/LAPTOP/Desktop/Estadística y Análisis Avanzado de datos/Entregables/ozone.csv")
View(ozone)
save.image("C:/Users/LAPTOP/Desktop/rprueba.RData")
load("C:/Users/LAPTOP/Desktop/rprueba.RData")
# mat1: matriz de 3 filas y 3 columnas de números enteros
mat1 <- matrix(c(10,20,30,10,50,40,50,10,5),nrow=3, ncol=3 )
# vec1: vector de 5 posiciones de números enteros
vec1 <- c(10,10,15,5,20)
# cad1: cadena de caracteres
cad1 <- "cadena"
#En base a los anteriores objetos realizar las siguientes acciones:
#- Crear una lista lista1 que contenga los tres objetos anteriores
lista1 <- list (matriz=mat1, vector=vec1, cadena=cad1)
# - Obtener el valor del tercer elemento de la lista
elem <- lista1[3]
# - Obtener el tercer elemento del vector de la lista
elem <- lista1$vector[3]
lista1
elem
vec1[3]
num<-vec1[3]
num
elem = lista1$vector[3]
elem
clientes <- c("id001", "id002", "id003","id001", "id002", "id003");
periodos <- c(201506,201506,201506,201507,201507,201507)
consumo <- c(20,30,50,10,20,40)
dataf1 <- data.frame(clientes=clientes,periodos=periodos,consumo=consumo)
dataf1
numreg <- nrow(dataf1)
numreg
dataf1$año <- round(dataf1$periodo/100)
dataf1
numreg <- nrow(dataf1)
dataf1$año <- round(dataf1$periodos/100)
dataf1$año
dataf2 <- subset(dataf1, consumo >= 20)
dataf2
dataf1$año <- round(dataf1$periodos)
dataf1$año
# Vectores que forman el data.frame
clientes <- c("id001", "id002", "id003","id001", "id002", "id003");
periodos <- c(201506,201506,201506,201507,201507,201507)
consumo <- c(20,30,50,10,20,40)
# Creamos el data.frame
dataf1 <- data.frame(clientes=clientes,periodos=periodos,consumo=consumo)
# Número de registros:
numreg <- nrow(dataf1)
numreg
dataf1
dataf1$año <- round(dataf1$periodos/100)
dataf1
View(dataf1)
datafmed <- aggregate(dataf1["consumo"], by=list(cliente=dataf1$cliente),
FUN=mean)
list(cliente=dataf1$cliente)
datafmed <- aggregate(dataf1["consumo"], by=list(cliente=dataf1$cliente),FUN=mean)
datafmed
datafmed <- aggregate(dataf1["consumo_media"], by=list(cliente=dataf1$cliente),FUN=mean)
colnames(datafmed)[2] <- "superduper"
datafmed
datafmed$ratio <- datafmed$consumo/mean(datafmed$consumo)
datafmed <- aggregate(dataf1["consumo"], by=list(cliente=dataf1$cliente),FUN=mean)
datafmed
datafmed$ratio <- datafmed$consumo/mean(datafmed$consumo)
datafmed$ratio
hist(dataf1$consumo)
datafper <- data.frame(periodos=c(201506,201507),
desc_periodo = c("Junio 2015","Julio 2015"))
datafper
hist(dataf1$consumo)
dataf1 <- merge(dataf1, datafper, "periodos")
dataf1
datafag <- aggregate(dataf1["consumo"], by=list(desc_periodo=dataf1$desc_periodo),
FUN=sum)
dataf1["consumo"]
list(desc_periodo=dataf1$desc_periodo)
datafag
plot(datafag$desc_periodo, datafag$consumo)
dataf1
install.packages("pmml")
# Crear una función que reciba tres vectores de 4 elementos y
# cree un data.frame con cada uno de los vectores como columna.
# Validar que todos los vectores tienen 4 elementos.
crearmat <- function(vec1, vec2, vec3){
if ((length(vec1) != 4) | (length(vec2) != 4) | (length(vec3) != 4)){
print("Número de elementos inválido")
} else
{
dataf <- data.frame(vec1,vec2,vec3)
return <- dataf
}
}
# Crear una función que reciba tres vectores de 4 elementos y
# cree un data.frame con cada uno de los vectores como columna.
# Validar que todos los vectores tienen 4 elementos.
crearmat <- function(vec1, vec2, vec3){
if ((length(vec1) != 4) | (length(vec2) != 4) | (length(vec3) != 4)){
print("Número de elementos inválido")
} else
{
dataf <- data.frame(vec1,vec2,vec3)
return <- dataf
}
}
vec1 <- c(1,1,1)
vec2 <- c(1,3,1,7)
vec3 <- c(4,2,1,0)
dataf <- crearmat(vec1,vec2,vec3)
dataf <- crearmat(vec1,vec2,vec3)
vec1 <- c(1,1,1,1)
vec2 <- c(1,3,1,7)
vec3 <- c(4,2,1,0)
dataf <- crearmat(vec1,vec2,vec3)
dataf
fun1 <- function(x){
y <- 3*x + 5
return(y)
}
vec1 <- sample(c(1,2,3,4,5), 10, replace=T, prob=c(0.25,0.25,0.25,0.25,0.25))
vecres <- sapply(vec1, FUN=fun1)
vecres
dataframe1<-data(iris)
dataframe1<-data(iris)
plot(iris)
data(iris)
plot(iris)
data(iris)
dataframe1<-data(iris)
plot(iris)
View(iris)
dataset1<-data(iris)
data.frame(dataset1)
View(iris)
data.frame(data(iris))
data.frame(data(iris))
iris<-data.frame(data(iris))
library(ggplot2)
install.packages(iris)
install.packages('datasets', ...)
install.packages('iris')
install.packages('datasets')
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
install.packages("datasets")
iris<-data.frame(data(iris))
library(ggplot2)
View(iris)
data.frame(data(iris))
tomates <- read.table(file = "tomates.csv", header = TRUE)
shiny::runApp('C:/Users/LAPTOP/Desktop/PFM/Tweet_Prediction')
runApp('C:/Users/LAPTOP/Desktop/PFM/Tweet_Prediction')
shiny::runApp('C:/Users/LAPTOP/Desktop/PFM/Tweet_Prediction')
runApp('C:/Users/LAPTOP/Desktop/PFM/Tweet_Prediction')
shiny::runApp('C:/Users/LAPTOP/Desktop/PFM/Tweet_Prediction')
#
# This is a Shiny web application. You can run the application by clicking
# the 'Run App' button above.
#
# Find out more about building applications with Shiny here:
#
#    http://shiny.rstudio.com/
#
library(shiny)
library(reshape2)
library(stringr)
library(RCurl)
library(RJSONIO)
library(tm)
library(ggplot2)
library(wordcloud)
rm(list = ls())
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
datos = read.csv("prueba.csv")
datos<-datos[1,] #Nos quedamos solo con la primera fila
datos[,1] = NULL
#datos[1:42]=0
datos$impresionesdiscret <- as.factor(datos$impresionesdiscret)
datos$impresionesdiscret=0
print(sapply(datos, typeof))
# CARGAR EL MODELO
# -----------------------------------------------------
modelo <-load(file = "randomforest.rda")
summary(modelo)
library(shiny)
library(reshape2)
library(stringr)
library(RCurl)
library(RJSONIO)
library(tm)
library(ggplot2)
library(wordcloud)
rm(list = ls())
datos = read.csv("prueba.csv")
shiny::runApp('C:/Users/LAPTOP/Desktop/PFM/Tweet_Prediction')
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
datos = read.csv("prueba.csv")
datos<-datos[1,] #Nos quedamos solo con la primera fila
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
datos = read.csv("prueba.csv")
rm(list = ls())
setwd('C:\\Users\\LAPTOP\\Desktop\\PFM\\Tweet_Prediction')
datos = read.csv("prueba.csv")
datos<-datos[1,] #Nos quedamos solo con la primera fila
datos[,1] = NULL
datos$impresionesdiscret <- as.factor(datos$impresionesdiscret)
datos$impresionesdiscret=0
print(sapply(datos, typeof))
modelo <- readRDS("randomforest.rda")
prediccion <- predict(modelo, datos, type="class")
rm(list = ls())
setwd('C:\\Users\\LAPTOP\\Desktop\\PFM\\Tweet_Prediction')
datos = read.csv("prueba.csv")
datos<-datos[1,] #Nos quedamos solo con la primera fila
datos[,1] = NULL
datos$impresionesdiscret <- as.factor(datos$impresionesdiscret)
datos$impresionesdiscret=0
print(sapply(datos, typeof))
modelo <- readRDS("randomforest.rda")
library(caret)
library(randomForest)
prediccion <- predict(modelo, datos, type="class")
rm(list = ls())
setwd('C:\\Users\\LAPTOP\\Desktop\\PFM\\Tweet_Prediction')
datos = read.csv("prueba.csv")
datos<-datos[1,] #Nos quedamos solo con la primera fila
datos[,1] = NULL
datos$impresionesdiscret <- as.factor(datos$impresionesdiscret)
datos$impresionesdiscret=0
print(sapply(datos, typeof))
modelo <- readRDS("randomforest.rda")
library(randomForest)
prediccion <- predict(modelo, datos, type="class")
runApp()
